%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\input{local-macros.tex}

\mathversion{sans}

\newcommand{\arrow}{\rightsquigarrow}

\newcommand{\restrict}[1]{\lvert_{#1}}
\newcommand{\pto}{\rightharpoonup}
\newcommand{\Univ}{\mathbb{U}}
\newcommand{\Un}{\mathcal{U}}

\newcommand{\arrowlift}{\ensuremath{lift}}
\newcommand{\arrowarr}{\ensuremath{arr}}
\newcommand{\arrowcomp}{\ensuremath{{>}\mspace{-6mu}{>}\mspace{-6mu}{>}}}
\newcommand{\arrowpair}{\ensuremath{\mathit{\&\mspace{-7.5mu}\&\mspace{-7.5mu}\&}}}
%\newcommand{\arrowpair}{\ensuremath{pair}}
\newcommand{\arrowif}{\ensuremath{ifte}}
\newcommand{\arrowlazy}{\ensuremath{lazy}}
\newcommand{\arrowapp}{\ensuremath{app}}
\newcommand{\arrowrun}{\ensuremath{run}}

\newcommand{\gen}{_\mathrm{a}}
\newcommand{\genb}{_\mathrm{b}}

\DeclareMathOperator{\botto}{\arrow_{\mspace{-3mu}\bot}}
\newcommand{\arrbot}{\arrowarr_{\mspace{-3mu}\bot}}
\newcommand{\compbot}{\arrowcomp_{\mspace{-5mu}\bot}}
\newcommand{\pairbot}{\arrowpair_{\mspace{-3mu}\bot}}
\newcommand{\ifbot}{\arrowif_{\mspace{-2mu}\bot}}
\newcommand{\lazybot}{\arrowlazy_{\mspace{-2mu}\bot}}

\newcommand{\map}{_\mathrm{map}}
\DeclareMathOperator{\mapto}{\arrow_{\mspace{-21mu}\map}}
%\DeclareMathOperator{\eqmap}{\mbox{\ensuremath{=_{\mspace{-19mu}\map}}}}
\newcommand{\liftmap}{\arrowlift\map}
\newcommand{\arrmap}{\arrowarr\map}
\newcommand{\compmap}{\arrowcomp\map}
\newcommand{\pairmap}{\arrowpair\map}
\newcommand{\ifmap}{\arrowif\map}
\newcommand{\lazymap}{\arrowlazy\map}

\newcommand{\pre}{_\mathrm{pre}}
\DeclareMathOperator{\preto}{\arrow_{\mspace{-19mu}\pre}}
%\DeclareMathOperator{\eqpre}{=_{\mspace{-17mu}\pre}}
\newcommand{\liftpre}{\arrowlift\pre}
\newcommand{\arrpre}{\arrowarr\pre}
\newcommand{\comppre}{\arrowcomp\pre}
\newcommand{\pairpre}{\arrowpair\pre}
\newcommand{\ifpre}{\arrowif\pre}
\newcommand{\lazypre}{\arrowlazy\pre}

\newcommand{\prepto}{\pto_{\mspace{-19mu}\pre}}


\begin{document}

\conferenceinfo{POPL '14}{January 22-24, 2014, San Diego, CA, USA}
\copyrightyear{2014}
\copyrightdata{[to be supplied]} 

%\titlebanner{banner above paper title}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Running Probabilistic Programs Backward}
%\subtitle{Subtitle Text, if any}

\authorinfo{Neil Toronto \and Jay McCarthy}
           {PLT @ Brigham Young University}
           {ntoronto@racket-lang.org \and jay@cs.byu.edu}
%\authorinfo{Chris Grant}
%           {Brigham Young University}
%           {grant@math.byu.edu}
\maketitle

\begin{abstract}
XXX
\end{abstract}

\category{XXX-CR-number}{XXX-subcategory}{XXX-third-level}

\terms
XXX, XXX

\keywords
XXX, XXX

\section{Introduction}

XXX: what we want to do, a bit about measure-theory's take on probability (especially preimage measure)

XXX: the paper starts with an overview of the insanely powerful $\lambda$-calculus we use, and an overview of arrows, the categorical construct we use to define the meaning of let-calculus expressions compositionally

For the bulk of this paper, we
\begin{enumerate}
	\item Define the \emph{bottom arrow}, type $X \botto Y$, as a compilation target for first-order functions that may raise errors.
	\item Derive the \emph{mapping arrow} from the bottom arrow, type $X \mapto Y$. Prove that its instances return extensional functions, or mappings, that compute the same values as corresponding bottom arrow computations.
	\item Derive the \emph{preimage arrow} from the mapping arrow, type $X \preto Y$. Prove that its instances compute preimages under corresponding mapping (or bottom) arrow instances.
	\item Extend the preimage arrow to handle partial functions.
	\item Approximate the preimage arrow by operating on rectangles instead of generally uncomputable sets.
\end{enumerate}
We report on our implementation of the bottom arrow and the approximating preimage arrow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Operational Metalanguage}

From here on, significant terms are introduced in \keyword{bold}, and significant terms we invent are introduced in \mykeyword{bold italics}.

We write all of the programs in this paper in \lzfclang~\cite{cit:toronto-2012flops-lzfc}, an untyped, call-by-value lambda calculus designed for deriving implementable programs from contemporary mathematics.

Contemporary mathematics is generally done in \keyword{ZFC}: \keyword{Zermelo-Fraenkel} set theory extended with the axiom of \keyword{Choice} (equivalently unique \keyword{Cardinality}).
ZFC has only first-order functions and no general recursion, which makes implementing a language defined by a transformation into contemporary mathematics quite difficult.
The problem is exacerbated if implementing the language requires approximation.
Targeting \lzfclang instead allows creating a precise mathematical specification and deriving an approximating implementation without changing languages.

In \lzfclang, essentially every set is a value, as well as every lambda and every set of lambdas.
All operations, including operations on infinite sets, are assumed to complete instantly if they terminate.\footnote{An
example of a nonterminating \lzfclang function is one that attempts to decide whether other \lzfclang programs halt.}

Almost everything definable in contemporary mathematics can be formally defined by a finite \lzfclang program, except objects that most mathematicians would agree are nonconstructive.
More precisely, any object that \emph{must} be defined by a statement of existence and uniqueness without giving a bounding set is not definable by a \emph{finite} \lzfclang program.

Because \lzfclang includes an inner model of ZFC, essentially every contemporary theorem applies to \lzfclang's set values without alteration.
Further, proofs about \lzfclang's set values apply to contemporary mathematical objects.\footnote{Assuming the existence of an inaccessible cardinal.}

In \lzfclang, algebraic data structures are encoded as sets; e.g. a \mykeyword{primitive ordered pair} of $x$ and $y$ is $\set{\set{x},\set{x,y}}$.
Only the \emph{existence} of encodings into sets is important, as it means data structures inherit a defining characteristic of sets: strictness.
More precisely, the lengths of paths to data structure leaves is unbounded, but each path must be finite.
Less precisely, data may be ``infinitely wide'' (such as $\Re$) but not ``infinitely tall'' (such as infinite trees and lists).

We assume data structures, including pairs, are encoded as \emph{primitive} ordered pairs with the first element a unique tag, so that they can be distinguished by checking tags.
Accessors such as $fst$ and $snd$ are trivial to define.

\lzfclang is untyped so its users can define an auxiliary type system that best suits their application area.
For this work, we use an informal, manually checked, polymorphic type system characterized by these rules:
\begin{itemize}
	\item A free lowercase type variable is universally quantified.
	\item A free uppercase type variable is a set.
	\item A set denotes a member of that set.
	\item $x \tto y$ denotes a partial function.
	\item $\pair{x,y}$ denotes a pair of values with types $x$ and $y$.
	\item $Set~x$ denotes a set with members of type $x$.
\end{itemize}
The type $Set~X$ denotes the same values as the powerset $\powerset~X$, or \emph{subsets} of $X$.
Similarly, the type $\pair{X,Y}$ denotes the same values as the product set $X \times Y$.

We write \lzfclang programs in heavily sugared $\lambda$-calculus syntax, with an $if$ expression and these additional primitives:
\begin{equation}
\begin{aligned}
	\begin{aligned}
		true &: Bool \\
		false &: Bool \\
		\emptyset &: Set~x \\
		\omega &: Ord \\
		take &: Set~x \tto x \\
	\end{aligned}
	&\tab
	\begin{aligned}
		(\in) &: x \tto Set~x \tto Bool \\
		\powerset &: Set~x \tto Set~(Set~x) \\
		\U &: Set~(Set~x) \tto Set~x \\
		image &: (x \tto y) \tto Set~x \tto Set~y \\
		card &: Set~x \tto Ord \\
	\end{aligned} \\
\end{aligned}
\label{eqn:lzfc-prims}
\end{equation}
Shortly, $\emptyset$ is the empty set, $\omega$ is the cardinality of the natural numbers, $take$ removes the member from a singleton set, $(\in)$ is an infix operator that decides membership, $\powerset$ returns all the subsets of a set, $\U$ returns the union of a set of sets, $image$ applies a function to each member of a set and returns the set of return values, and $card$ returns the cardinality of a set.

We assume literal set notation such as $\set{0,1,2}$ is already defined in terms of set primitives.

\subsection{Internal and External Equality}

Set theory extends first-order logic with an axiom that defines equality to be extensional, and with axioms that ensure the existence of sets in the domain of discourse.
\lzfclang is defined the same way as any other operational $\lambda$-calculus: by (conservatively) extending the domain of discourse with expressions and defining a reduction relation.

While \lzfclang does not have an equality primitive, set theory's extensional equality can be recovered internally using $(\in)$.
\emph{Internal} extensional equality is defined by
\begin{equation}
	x = y \ := \ x \in \set{y}
\end{equation}
which means
\begin{equation}
	(=) \ := \ \fun{x}\fun{y}{x \in \set{y}}
\end{equation}
Thus, $1 = 1$ reduces to $1 \in \set{1}$, which reduces to $true$.\footnote{Technically, \lzfclang has a big-step semantics, and $1 \in \set{1}$ can be extracted from the derivation tree for $1 = 1$.}
Because of the particular way \lzfclang's lambda terms are defined, for two lambda terms $f$ and $g$, $f = g$ reduces to $true$ when $f$ and $g$ are structurally identical modulo renaming.
For example, $(\fun{x}{x}) = (\fun{y}{y})$ reduces to $true$, but $(\fun{x}{2}) = (\fun{x}{1+1})$ reduces to $false$.

We understand any \lzfclang term $\mathit{e}$ used as a truth statement as shorthand for ``$\mathit{e}$ reduces to $true$.''
Therefore, while the terms $(\fun{x}{x})~1$ and $1$ are (externally, extensionally) unequal, we can say that $(\fun{x}{x})~1 = 1$.

Any truth statement $\mathit{e}$ implies that $\mathit{e}$ converges.
In particular, the truth statement $\mathit{e}_1 = \mathit{e}_2$ implies that both $\mathit{e}_1$ and $\mathit{e}_2$ converge.
However, we often want to say that $\mathit{e}_1$ and $\mathit{e}_1$ are equivalent when they both diverge.
In these cases, we use a slightly weaker equivalence.

\begin{definition}[observational equivalence]
Two \lzfclang terms $\mathit{e_1}$ and $\mathit{e_2}$ are \keyword{observationally equivalent}, written $\mathit{e_1} \equiv \mathit{e_2}$, when $\mathit{e_1} = \mathit{e_2}$ or both $\mathit{e_1}$ and $\mathit{e_2}$ diverge.
\end{definition}

It could be helpful to introduce even coarser notions of equivalence, such as applicative or logical bisimilarity.
However, we do not want internal equality and external equivalence to differ too much.
We therefore introduce type-specific notions of equivalence as needed.

\subsection{Additional Functions and Forms}

XXX: lambda syntactic sugar: automatic currying (including the two-argument primitives $(\in)$ and $image$), matching, sectioning rules

XXX: set syntactic sugar: set comprehensions, cardinality, indexed unions

XXX: functions: $\u$, $\i$, $\w$, $\subseteq$

\begin{equation}
\begin{aligned}
	&(\uplus) : Set~x \tto Set~x \tto Set~x \\
	&A \uplus B \ := \ if~(A \i B = \emptyset)~(A \u B)~(take~\emptyset)
\end{aligned}
\end{equation}

XXX: logic: logical operators and quantifiers

In set theory, functions are encoded as sets of input-output pairs.
The increment function for the natural numbers, for example, is $\set{\pair{0,1},\pair{1,2},\pair{2,3},...}$.
To distinguish these hash tables from lambdas, we call them \mykeyword{mappings}, and use the word \keyword{function} for either a lambda or a mapping.
For convenience, as with lambdas, we use adjacency (i.e. $(f~x)$) to apply mappings.

The set $X \pto Y$ contains all the \emph{partial} mappings from $X$ to $Y$.
For example, $X \pto Y$ is the return type for the restriction function:
\begin{equation}
\begin{aligned}
	&(\cdot)\restrict{(\cdot)}\ : (X \tto Y) \tto Set~X \tto (X \pto Y) \\
	&f\restrict{A} \ := \ image~(\fun{x}{(x, f~x)})~A
\end{aligned}
\end{equation}
which converts a lambda or a mapping to a mapping with domain $A \subseteq X$.
To create mappings using lambda syntax, we define $\fun{\mathit{x} \in \mathit{e_A}}{\mathit{e}}$ as shorthand for $(\fun{\mathit{x}}{\mathit{e}})\restrict{\mathit{e_A}}$.

\begin{figure*}[t]\centering
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		&domain : (X \pto Y) \tto Set~X \\
		&domain \ := \ image~fst \\
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&range : (X \pto Y) \tto Set~Y \\
		&range \ := \ image~snd
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&preimage : (X \pto Y) \tto Set~Y \tto Set~X \\
		&preimage~f~B \ :=\ \setb{x \in domain~f}{f~x \in B}
	\end{aligned} \\
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\pair{\cdot,\cdot}\map : (X \pto Y_1) \tto (X \pto Y_2) \tto (X \pto Y_1 \times Y_2) \\
		&\pair{g_1,g_2}\map \ := \ 
			\lzfclet{
				A & (domain~g_1) \i (domain~g_2)
			}{\fun{x \in A}{\pair{g_1~x,g_2~x}}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\circ\map) : (Y \pto Z) \tto (X \pto Y) \tto (X \pto Z) \\
		&g_2 \circ\map g_1 \ := \ 
			\lzfclet{
				A & preimage~g_1~(domain~g_2)
			}{\fun{x \in A}{g_2~(g_1~x)}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\uplus\map) : (X \pto Y) \tto (X \pto Y) \tto (X \pto Y) \\
		&g_1 \uplus\map g_2 \ := \ 
			\lzfclet{
				A & (domain~g_1) \uplus (domain~g_2)
			}{\fun{x \in A}{if~(x \in domain~g_1)~(g_1~x)~(g_2~x)}}
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Operations on mappings.}
\label{fig:mapping-defs}
\end{figure*}

Figure~\ref{fig:mapping-defs} defines more operations on partial mappings: $domain$, $range$, $preimage$, pairing, composition, and disjoint union.
The latter three are particularly important in the preimage arrow's derivation, and $preimage$ is critical in measure theory's account of probability.

XXX: lazy mappings

XXX: total mappings are infinite vectors

XXX: projection functions
\begin{align}
&\begin{aligned}
	&\pi : J \tto (J \to X) \tto X \\
	&\pi~j~f \ := \ f~j
\end{aligned} \\
\nonumber \\[-6pt]
&\begin{aligned}
	&proj : J \tto (J \to X) \tto Set~X \\
	&proj~j~A \ := \ image~(\pi~j)~A
\end{aligned}
\end{align}


\begin{comment}
\subsection{Ordinal Numbers and Transfinite Recursion}

The \keyword{ordinal numbers}, or values of type $Ord$, are an extension of the natural numbers to infinite lengths.
Ordinals are typically defined as the smallest sets that contain all their predecessors; e.g. the first four are
\begin{equation}
\begin{aligned}
	\begin{aligned}
		0 &\ := \ \emptyset \\
		1 &\ := \ \set{0}
	\end{aligned}
	&\tab\tab
	\begin{aligned}
		2 &\ := \ \set{0,1} \\
		3 &\ := \ \set{0,1,2}
	\end{aligned}
\end{aligned}
\end{equation}
The smallest infinite ordinal $\omega$ is the set of all finite ordinals.
Other infinite ordinals are defined in terms of $\omega$:
\begin{equation}
\begin{aligned}
	\omega &\ := \ \set{0,1,2,3,...} \\
	\omega+1 &\ := \ \set{0,1,2,3,...,\omega} \\
	\omega+2 &\ := \ \set{0,1,2,3,...,\omega,\omega+1} \\
	\omega+\omega &\ := \ \set{0,1,2,3,...,\omega,\omega+1,\omega+2,...}
\end{aligned}
\end{equation}
The above sets are all countable, meaning that their cardinality is $\omega$.
Generally, any ordinal $\alpha$ for which $\alpha = |\alpha|$ is also called a \keyword{cardinal number}.%\footnote{Think of ordinals as lengths of ordered collections, and cardinals as sizes of unordered collections.}

Ordinals are totally ordered by membership; i.e. $\beta < \alpha$ is equivalent to $\beta \in \alpha$.
Ordinals with an immediate predecessor (such as $3$ and $\omega+2$) are called \keyword{successor ordinals}.
Nonzero ordinals without an immediate predecessor (roughly, those whose literal representations end in ``$...$'') are called \keyword{limit ordinals}.

Limit ordinals allow writing terminating functions that recur infinitely many times.
Suppose we wanted a function that recursively generates all the integral successors of $0.5$.
Consider this first attempt, which can be written in any Turing-equivalent language:
\begin{equation}
\begin{aligned}
	&succs : \omega \tto Set~\Re \tto Set~\Re \\
	&\lzfcsplit{
		&succs~n~A \ := \ \\
		&\tab\lzfccase{n}{
			0 & A \\
			m+1 & A \u (image~(+~1.0)~(succs~m~A))
		}
	}
\end{aligned}
\end{equation}
This unfold over finite ordinals generates prefixes such as
\begin{equation}
\begin{aligned}
	succs~0~\set{0.5} &\ = \ \set{0.5} \\
	succs~1~\set{0.5} &\ = \ \set{0.5, 1.5} \\
	succs~2~\set{0.5} &\ = \ \set{0.5, 1.5, 2.5}
\end{aligned}
\end{equation}
but will never generate the full set of integral successors.

To close $\set{0.5}$ under increment, we can use \keyword{transfinite recursion}: unfolding over ordinals as above, but using an additional inductive case for limit ordinals:
\begin{equation}
\begin{aligned}
	&succs : Ord \tto Set~\Re \tto Set~\Re \\
	&\lzfcsplit{
		&succs~\alpha~A \ := \ \\
		&\tab\lzfccase{\alpha}{
			0 & A \\
			\beta+1 & A \u (image~(+~1.0)~(succs~\beta~A)) \\
			else & \U\limits_{\beta < \alpha} succs~\beta~A
		}
	}
\end{aligned}
\end{equation}
With this, we can compute the closure as desired:
\begin{equation}
\begin{aligned}
	&succs~\omega~\set{0.5} \ \\
		&\tab = \ (succs~0~\set{0.5}) \u (succs~1~\set{0.5}) \u \cdots \\
		&\tab = \ \set{0.5, 1.5, 2.5, 3.5, ...}
\end{aligned}
\end{equation}
The function terminates because each branch, though unbounded, is finite in length.
As with strict data structures, the shape of the computation is ``infinitely wide'' but not ``infinitely tall.''

The $succs$ function is a special case of a powerful general closure operator defined by
\begin{equation}
\begin{aligned}
	&close : (Set~x \tto Set~x) \tto Ord \tto Set~x \tto Set~x \\
	&close~f~\alpha~A \ := \ 
		\lzfccase{\alpha}{
			0 & A \\
			\beta+1 & A \u (f~(close~f~\beta~A)) \\
			else & \U\limits_{\beta < \alpha} close~f~\beta~A
		}
\end{aligned}
\end{equation}
With this, $succs := close~(image~(+~1.0))$.

The $close$ function can construct the least fixpoint of any monotone set function, if a fixpoint exists.
Such fixpoints include the languages of context-free grammars and the reduction relations defined by inductive rules in operational semantics.
(For almost all of these, only countably many iterations is sufficient.)
We will use $close$ to construct $\sigma$-algebras and preimages, two of the main objects of study in measure theory.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Measure Theory}

XXX: overview, with analogies to topology

\subsection{Sigma-Algebras}

XXX: motivate and define informally

\allowdisplaybreaks

Formally, using the following functions to generate $\emptyset$, complements, and countable unions from families of any type $x$:
\begin{align}
	&\begin{aligned}
		&\sigma@comps : Set~(Set~x) \tto Set~(Set~x) \\
		&\sigma@comps~\A \ := \ \setb{A \w A'}{A, A' \in \A} \\
	\end{aligned} \\
\nonumber \\[-6pt]
	&\begin{aligned}
		&\sigma@unions : Set~(Set~x) \tto Set~(Set~x) \\
		&\sigma@unions~\A \ := \ \setb{\U\A'}{\A' \subseteq \A \band |\A'| \leq \omega} \\
	\end{aligned} \\
\nonumber \\[-6pt]
	&\begin{aligned}
		&\sigma@ops : Set~(Set~x) \tto Set~(Set~x) \\
		&\sigma@ops~\A \ := \ \set{\emptyset} \u (\sigma@comps~\A) \u (\sigma@unions~\A) \\
	\end{aligned}
\end{align}
the following function identifies $\sigma$-algebras:
\begin{equation}
\begin{aligned}
	&\sigma@algebra? : Set~(Set~x) \tto Bool \\
	&\sigma@algebra?~\A \ := \ (\sigma@ops~\A) \subseteq \A
\end{aligned}
\end{equation}

Clearly, $\powerset~A$ for any set $A$ is a $\sigma$-algebra.
Unfortunately, this $\sigma$-algebra is ``too large''---a concept we will formalize when discussing measures.
(XXX: cover earlier, in motivation, using Banach-Tarski paradox?)

The \keyword{trace} of a family of subsets $\A$ with a set $A$ is the result of intersecting every $A' \in \A$ with $A$:
\begin{equation}
\begin{aligned}
	&trace : Set~(Set~x) \tto Set~x \tto Set~(Set~x) \\
	&trace~\A~A \ := \ \setb{A \i A'}{A' \in \A} \\
	&\A\restrict{A} \ := \ trace~\A~A
\end{aligned}
\end{equation}

\begin{lemma}[traces of $\sigma$-algebras are $\sigma$-algebras]
For any $\sigma$-algebra $\A$ and set $A$, $trace~\A~A$ is a $\sigma$-algebra on $A \i \U\A$.
\end{lemma}

\begin{lemma}[$\sigma@close$ distributes over $trace$]
For any family of subsets $\A$ and set $A$, $\sigma@close~(trace~\A~A) = trace~(\sigma@close~\A)~A$.
\label{lem:close-distributes-over-trace}
\end{lemma}


\subsection{Measurable Mappings}

XXX: define and characterize measurable mappings

XXX: images of measurable sets under measurable functions are not always measurable; e.g. projections

\subsection{Generated Sigma-Algebras}

Often, $\sigma$-algebras are too complicated to work with directly.
In such cases, we reason about them in terms of \keyword{generating families}: simpler families of sets that, when closed under $\sigma$-algebra operations, are $\sigma$-algebras with nice properties.

To generate $\sigma$-algebras, first note that $\sigma@ops$ is monotone and has an upper bound (the powerset $\sigma$-algebra).
Therefore, $close$ can generate a least fixpoint from it:
\begin{equation}
\begin{aligned}
	&\sigma@close : Set~(Set~x) \tto Set~(Set~x) \\
	&\sigma@close \ := \ close~\sigma@ops~\omega_1
\end{aligned}
\end{equation}
Here, $\omega_1$ is the \keyword{first uncountable ordinal}, or the least ordinal containing every countable ordinal.\footnote{\lzfclang does not decide the continuum hypothesis; i.e. whether $\omega_1 = |\Re|$.}

\begin{lemma}[generated $\sigma$-algebras]
Let $\A$ be a family of sets and $\A' := \sigma@close~\A$.
Then $\A'$ is the smallest $\sigma$-algebra for which $\A \subseteq \A'$.
\label{lem:generated-sigma-algebra}
\end{lemma}

Perhaps the most well-studied generated $\sigma$-algebras are \keyword{Borel $\sigma$-algebras}: those generated from topologies.
For example, if $\tau$ is the standard topology on $\Re$, containing the open intervals and uncountable unions of open intervals, then $\sigma@close~\tau$ is the Borel $\sigma$-algebra for that topology, containing all intervals (open, closed and half-open), and their countable unions and complements.

Other well-studied, generated $\sigma$-algebras are \keyword{product $\sigma$-algebras}: those generated from the rectangles of, or the pairwise products of sets from, other $\sigma$-algebras.
For example, the product $\sigma$-algebra $\A_1 \otimes \A_2$ can be defined by
\begin{align}
	&\begin{aligned}
		&(\boxtimes) : Set~(Set~x) \tto Set~(Set~y) \tto Set~(Set~\pair{x,y}) \\
		&\A_1 \boxtimes \A_2 \ := \ \setb{A_1 \times A_2}{A_1 \in \A_1, A_2 \in \A_2} \\
	\end{aligned} \\
\nonumber \\[-6pt]
	&\begin{aligned}
		&(\otimes) : Set~(Set~x) \tto Set~(Set~y) \tto Set~(Set~\pair{x,y}) \\
		&\A_1 \otimes \A_2 \ := \ \sigma@close~(\A_1 \boxtimes \A_2) \\
	\end{aligned}
\end{align}
However, the following theorem is usually taken (somewhat less constructively) as the definition of $\A_1 \otimes \A_2$.
\begin{lemma}[projection mappings are product-measurable]
Let $\A := \A_1 \otimes \A_2$ and $A := \U\A$.
Then $\A$ is the smallest $\sigma$-algebra for which $fst\restrict{A}$ is $\A-\A_1$-measurable and $snd\restrict{A}$ is $\A-\A_2$-measurable.
\end{lemma}

\subsection{Measures and Probabilities}

Now that we have defined what sets can be measured, we can define what it means to measure them.

\begin{definition}[Measure]
A mapping $\mu \in \powerset~X \pto [0,\infty)$ is a \keyword{measure} if
\begin{itemize}
	\item $domain~\mu$ is a $\sigma$-algebra on $X$.
	\item $\mu~\emptyset = 0$.
	\item For all $\A' \subseteq \A$ such that $|\A'| \leq \omega$, $\sum\limits_{A \in \A'} (\mu~A) = \mu~(\U \A')$.
\end{itemize}
\end{definition}

XXX: Probabilities of output sets are preimage measures: if $f \in A \pto B$ is $\A-\B$-measurable and $\P \in \A \to [0,1]$, then
\begin{equation}
	\P~(preimage~f~B)
\end{equation}
is the probability of $B$.

XXX: more explanation, and an example
\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Arrows and First-Order Semantics}

XXX: really short arrow intro (XXX: cite Hughes, Lindley et al)

\subsection{Alternative Arrow Definitions}

For every arrow $a$ in this paper, we do not give a typical minimal definition.
Instead of $first\gen$, we define $(\arrowpair\gen)$---typically called \keyword{fanout}, but its use will be clearer if we call it \keyword{pairing}---which applies two functions to an input and returns the pair of their outputs.
Though $first\gen$ may be defined in terms of $(\arrowpair\gen)$ and vice-versa~\cite{cit:hughes-2005afp-arrows}, we give $(\arrowpair\gen)$ definitions in this paper because the applicable contemporary theorems are in terms of pairing functions.

One way to strengthen an arrow $a$ is to define an additional combinator $left\gen$, which can be used to choose an arrow computation based on the result of another.
Again, we define a different combinator, $\arrowif\gen$, to make it easier to apply contemporary theorems, which are in terms of disjoint unions of mappings instead of explicit disjoint union types.

In a nonstrict $\lambda$-calculus, simply defining a choice combinator allows writing recursive functions using nothing but arrow combinators and lifted, pure functions.
However, any strict $\lambda$-calculus (such as \lzfclang) requires an extra combinator to defer computations in conditional branches.

For example, suppose we define the \keyword{function arrow} with choice, by defining
\begin{equation}
\begin{aligned}
	\arrowarr~f &\ := \ f \\
	(f_1~\arrowcomp~f_2)~a &\ := \ f_2~(f_1~a) \\
	(f_1~\arrowpair~f_2)~a &\ := \ \pair{f_1~a,f_2,a} \\
	\arrowif~f_1~f_2~f_3~a &\ := \ if~(f_1~a)~(f_2~a)~(f_3~a) \\
\end{aligned}
\label{eqn:function-arrow}
\end{equation}
and try to define the following recursive function:
\begin{equation}
	halt@on@true \ := \ \arrowif~(\arrowarr~id)~(\arrowarr~id)~halt@on@true
\end{equation}
The defining expression diverges in a strict $\lambda$-calculus.
In a nonstrict $\lambda$-calculus, it diverges only when applied to $false$.

Using $\arrowlazy~f~a := f~0~a$, which receives thunks and returns arrow computations, we can write $halt@on@true$ as
\begin{equation}
\begin{aligned}
	&halt@on@true \ := \ 
	\arrowif~(\arrowarr~id)~(\arrowarr~id)~(\arrowlazy~\fun{0}{halt@on@true})
\end{aligned}
\end{equation}
which diverges only when applied to $false$ in any $\lambda$-calculus.

\begin{definition}[arrow+choice]A binary type constructor $(\arrow\gen)$ and the combinators
\begin{equation}
\begin{aligned}
	\arrowarr\gen &: (x \tto y) \tto (x \arrow\gen y)
\\
	(\arrowcomp\gen) &: (x \arrow\gen y) \tto (y \arrow\gen z) \tto (x \arrow\gen z)
\\
	(\arrowpair\gen) &: (x \arrow\gen y) \tto (x \arrow\gen z) \tto (x \arrow\gen \pair{y,z})
\end{aligned}
\label{eqn:arrow-combinators}
\end{equation}
define an \keyword{arrow} if certain monoid, homomorphism, and structural laws hold.
The additional combinators
\begin{equation}
\begin{aligned}
	\arrowif\gen &: (x \arrow\gen Bool) \tto (x \arrow\gen y) \tto (x \arrow\gen y) \tto (x \arrow\gen y)
\\
	\arrowlazy\gen &: (1 \tto (x \arrow\gen y)) \tto (x \arrow\gen y)
\end{aligned}
\end{equation}
define an \keyword{arrow+choice} if certain additional homomorphism and structural laws hold.
(The $\arrowlazy\gen$ combinator may be omitted in nonstrict or strongly normalizing languages.)
\end{definition}

The necessary homomorphism laws ensure that $\arrowarr\gen$ distributes over function arrow combinators.
These laws can be put in terms of more general homomorphism properties that deal with distributing an arrow-to-arrow lift, which we use extensively to prove correctness.

\begin{definition}[arrow+choice homomorphism]
A function $lift\genb : (x \arrow\gen y) \tto (x \arrow\genb y)$ is an \mykeyword{arrow homomorphism} from arrow $\mathrm{a}$ to arrow $\mathrm{b}$ if the following distributive laws hold for appropriately typed $f$, $f_1$ and $f_2$:
\begin{align}
	lift\genb~(\arrowarr\gen~f) &\ \equiv \ \arrowarr\genb~f
	\label{eqn:lift-distributes-over-arr}
\\
	lift\genb~(f_1~\arrowcomp\gen~f_2) &\ \equiv \ (lift\genb~f_1)~\arrowcomp\genb~(lift\genb~f_2)
	\label{eqn:lift-distributes-over-comp}
\\
	lift\genb~(f_1~\arrowpair\gen~f_2) &\ \equiv \ (lift\genb~f_1)~\arrowpair\genb~(lift\genb~f_2)
	\label{eqn:lift-distributes-over-pair}
\end{align}
It is an \mykeyword{arrow+choice homomorphism} if, additionally,
\begin{align}
	\arrowlift\genb~(\arrowif\gen~f_1~f_2~f_3) &\ \equiv \ 
		\arrowif\genb~(lift\genb~f_1)~(lift\genb~f_2)~(lift\genb~f_3)
	\label{eqn:lift-distributes-over-if}
\\
	\arrowlift\genb~(\arrowlazy\gen~f) &\ \equiv \
		\arrowlazy\genb~\fun{0}{\arrowlift\genb~(f~0)}
	\label{eqn:lift-distributes-over-lazy}
\end{align}
hold for appropriately typed $f$, $f_1$, $f_2$ and $f_3$.
\label{def:arrow-homomorphism}
\end{definition}

The homomorphism laws state that $\arrowarr\gen$ must be a homomorphism from the function arrow+choice to arrow $a$.

The monoid and structural arrow laws play little role in our semantics or its correctness.
For the arrows we define, then, we elide the proofs of these arrow laws, and concentrate on homomorphisms.


\subsection{First-Order Let-Calculus Semantics}

XXX: Figure~\ref{fig:semantic-function}...

XXX: Stack machine...

XXX: Roughly, first-order application $(\mathit{x~e})$ runs arrow computation $\mathit{x}$ with a fresh stack with $\mathit{e}$ at the head.
The binding form $(let~\mathit{e}_0~\mathit{e_b})$ pushes $\mathit{e}_0$ onto the stack.
Variables are referenced using $(env~\mathit{n})$ with $(env~0)$ referring to the head.

\begin{figure*}[t]\centering
\begin{align*}
\begin{aligned}[t]
	\meaningof{\mathit{x} := \mathit{e};\ \cdots}\gen &\ :\equiv\
		\mathit{x} := \meaningof{\mathit{e}}\gen;\ \cdots \\
	\meaningof{\mathit{x}~\mathit{e}}\gen &\ :\equiv\
		\meaningof{\pair{\mathit{e},0}}\gen~\arrowcomp\gen~\mathit{x}
\\
	\meaningof{\pair{\mathit{e}_1,\mathit{e}_2}}\gen &\ :\equiv\
		\meaningof{\mathit{e}_1}\gen~\arrowpair\gen~\meaningof{\mathit{e}_2}\gen
\\
	\meaningof{let~\mathit{e}_0~\mathit{e_b}}\gen &\ :\equiv\ 
		(\meaningof{\mathit{e}_0}\gen~\arrowpair\gen~(\arrowarr\gen~id))~
			\arrowcomp\gen~
		\meaningof{\mathit{e_b}}\gen
\\
	\meaningof{env~\mathit{n}}\gen &\ :\equiv\ \arrowarr\gen~\fun{\gamma}{\gamma_\mathit{n}}
\\
	\meaningof{if~\mathit{e_c}~\mathit{e_t}~\mathit{e_f}}\gen &\ :\equiv\
		\arrowif\gen~
			\meaningof{\mathit{e_c}}\gen~
			(\arrowlazy\gen~\fun{0}{\meaningof{\mathit{e_t}}\gen})~
			(\arrowlazy\gen~\fun{0}{\meaningof{\mathit{e_f}}\gen})
\\
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	\meaningof{\mathit{v}}\gen &\ :\equiv\ \arrowarr\gen~\fun{\gamma}{\mathit{v}}
\\
	\meaningof{fst~\mathit{e}}\gen &\ :\equiv\
		\meaningof{\mathit{e}}\gen~\arrowcomp\gen~(\arrowarr\gen~fst)
\\
	\meaningof{snd~\mathit{e}}\gen &\ :\equiv\
		\meaningof{\mathit{e}}\gen~\arrowcomp\gen~(\arrowarr\gen~snd)
\\
	\meaningof{\mathit{e}_1 = \mathit{e}_2}\gen &\ :\equiv\
		\meaningof{\pair{\mathit{e}_1,\mathit{e}_2}}\gen~\arrowcomp\gen~(\arrowarr\gen~\fun{\pair{x,y}}{x = y})
\\
	\meaningof{\mathit{e}_1 + \mathit{e}_2}\gen &\ :\equiv\
		\meaningof{\pair{\mathit{e}_1,\mathit{e}_2}}\gen~\arrowcomp\gen~(\arrowarr\gen~\fun{\pair{x,y}}{x+y})
\\
	&\ \cdots\ 
\\
\end{aligned}
\end{align*}
\hrule
\caption{Transformation from a let-calculus with first-order definitions and De-Bruijn-indexed bindings to computations in arrow $\mathrm{a}$.
%The type of a transformed expression is $1 \arrow\gen X$, or an arrow from the empty stack $\gamma = 0$ to a value of type $X$.
}
\label{fig:semantic-function}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Bottom and Mapping Arrows}

We are certain that the preimage arrow correctly computes preimages under some function $f$ because we ultimately \emph{derive} it from a simpler arrow used to construct $f$.

One obvious candidate for the simpler arrow is the function arrow, defined in~\eqref{eqn:function-arrow}.
However, it will be necessary to explicitly handle nonterminating functions, so we need a slightly more complicated arrow for which running computations may raise an error.

Figure~\ref{fig:bottom-arrow-defs} defines the \mykeyword{bottom arrow}.
Its computations are of type $x \botto y ::= x \tto y_\bot$, where the inhabitants of $y_\bot$ are the error value $\bot$ as well as the inhabitants of $y$. The type $Bool_\bot$, for example, denotes the members of $Bool \u \set{\bot}$.

\begin{figure*}[t]\centering
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\arrbot : (x \tto y) \tto (x \botto y) \\
		&\arrbot~f \ := \ f
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\compbot) : (x \botto y) \tto (y \botto z) \tto (x \botto z) \\
		&(f_1~\compbot~f_2)~x \ := \ if~(f_1~x = \bot)~\bot~(f_2~(f_1~x))
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\pairbot) : (x \botto {y_1}) \tto (x \botto {y_2}) \tto (x \botto \pair{y_1,y_2}) \\
		&(f_1~\pairbot~f_2)~x \ := \ if~(f_1~x = \bot~or~f_2~x = \bot)~\bot~{\pair{f_1~x,f_2~x}}
	\end{aligned}
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\ifbot : (x \botto Bool) \tto (x \botto y) \tto (x \botto y) \tto (x \botto y) \\
		&\ifbot~f_1~f_2~f_3~x \ := \
			\lzfccase{f_1~x}{true & f_2~x \\ false & f_3~x \\ else & \bot}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&\lazybot : (1 \tto (x \botto y)) \tto (x \botto y) \\
		&\lazybot~f~x \ := \ f~0~x
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Bottom arrow definitions.}
\label{fig:bottom-arrow-defs}
\end{figure*}

\begin{theorem}
$\arrbot$, $(\pairbot)$ and $(\compbot)$ define an arrow.
With $\ifbot$ and $\lazybot$, they define an arrow+choice.
\end{theorem}
\begin{proof}
The bottom arrow is the Maybe monad's Kleisli arrow with $Nothing = \bot$.
\end{proof}

\subsection{Deriving the Mapping Arrow}

Theorems in measure theory tend to be about mappings, not lambdas.
As in intermediate step toward the preimage arrow, then, we need an arrow whose computations produce mappings or are mappings themselves.

It is tempting to try to define the mapping arrow's type constructor using $X \mapto Y ::= X \pto Y$, and define $f_1~\compmap~f_2 := f_2 \circ\map f_1$ and $(\pairmap) := \pair{\cdot,\cdot}\map$.
Unfortunately, we run into a problem defining $\arrmap : (X \tto Y) \tto (X \pto Y)$: we cannot define it as $\arrmap~f := f\restrict{X}$. Although $X$ is a \lzfclang value, it is not in scope in $\arrmap$'s definition because it is only part of the type.

We need to parameterize computations on a domain, so we define the \mykeyword{mapping arrow} computation type as
\begin{equation}
	X \mapto Y \ ::= \ Set~X \tto (X \pto Y)
\end{equation}
Notice that $\bot$ is absent in $Set~X \tto (X \pto Y)$.
This will make it easier to disregard nonterminating inputs when computing preimages further on. (XXX: section)

To make the correspondence between bottom arrow and mapping arrow computations as clear as possible,
we start by defining a function $\liftmap : (X \botto Y) \tto (X \mapto Y)$ to lift bottom arrow computations.
It must restrict its argument $f$'s domain to a subset of $X$ for which $f$ does not return $\bot$.
It is helpful to have a standalone function $domain_\bot$ that computes such domains, so we define that first, and then define $\liftmap$ in terms of it:
\begin{align}
	&\begin{aligned}
		&domain_\bot : (X \botto Y) \tto Set~X \tto Set~X \\
		&domain_\bot~f~A \ := \ preimage~f\restrict{A}~((image~f~A) \w \set{\bot})
	\end{aligned} \\
\nonumber \\[-6pt]
	&\begin{aligned}
		&\liftmap : (X \botto Y) \tto (X \mapto Y) \\
		&\liftmap~f~A \ := \ \lzfclet{A' & domain_\bot~f~A}{f\restrict{A'}}
	\end{aligned}
\end{align}

The clearest way to ensure that mapping arrow computations mean what we think they mean is to derive each combinator in a way that makes $\liftmap$ distribute over bottom arrow computations; i.e. it must be an arrow+choice homomorphism (Definition~\ref{def:arrow-homomorphism}).
Less generally but more concretely, for any let-calculus expression $\mathit{e}$, we would like $\meaningof{\mathit{e}}\map \equiv \liftmap~\meaningof{\mathit{e}}_\bot$.

To meet the homomorphism laws, we need equivalence to be more extensional for mapping computations.

\begin{definition}[mapping arrow equivalence]
Two mapping arrow computations $g_1 : X \mapto Y$ and $g_2 : X \mapto Y$ are equivalent, or $g_1 \equiv g_2$, when $g_1~A \equiv g_2~A$ for all $A \subseteq X$.
\end{definition}

Clearly $\arrowarr\genb := lift\genb \circ \arrowarr\gen$ meets the first homomorphism identity~\eqref{eqn:lift-distributes-over-arr}, so we define $\arrmap$ as a composition.
The following subsections derive $(\pairmap)$, $(\compmap)$, $\ifmap$ and $\lazymap$ from their corresponding bottom arrow combinators, in a way that ensures $\liftmap$ is an arrow+choice homomorphism.
Figure~\ref{fig:mapping-arrow-defs} contains the resulting definitions.

\begin{figure*}[t]\centering
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		X \mapto Y \ ::= \ Set~X \tto (X \pto Y)
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&\arrmap : (X \tto Y) \tto (X \mapto Y) \\
		&\arrmap \ := \ \liftmap \circ \arrbot
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\compmap) : (X \mapto Y) \tto (Y \mapto Z) \tto (X \mapto Z) \\
		&(g_1~\compmap~g_2)~A \ := \ 
			\lzfclet{
				g_1' & g_1~A \\
				g_2' & g_2~(range~g_1')
			}{g_2' \circ\map g_1'}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\pairmap) : (X \mapto Y_1) \tto (X \mapto Y_2) \tto (X \mapto \pair{Y_1,Y_2}) \\
		&(g_1~\pairmap~g_2)~A \ := \ \pair{g_1~A,g_2~A}\map
	\end{aligned} \\
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\ifmap : (X \mapto Bool) \tto (X \mapto Y) \tto (X \mapto Y) \tto (X \mapto Y) \\
		&\ifmap~g_1~g_2~g_3~A \ := \ 
			\lzfclet{
				g_1' & g_1~A \\
				g_2' & g_2~(preimage~g_1'~\set{true}) \\
				g_3' & g_3~(preimage~g_1'~\set{false})
			}{g_2' \uplus\map g_3'}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&\lazymap : (1 \tto (X \mapto Y)) \tto (X \mapto Y) \\
		&\lazymap~g~A \ := \ if~(A = \emptyset)~\emptyset~(g~0~A)
	\end{aligned} \\
\\[-6pt]
\hline
\\[-6pt]
	&\begin{aligned}[t]
		&\liftmap : (X \botto Y) \tto (X \mapto Y) \\
		&\liftmap~f~A \ := \ \setb{\pair{x,y} \in f\restrict{A}}{y \neq \bot}
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Mapping arrow definitions.}
\label{fig:mapping-arrow-defs}
\end{figure*}

\subsection{Case: Pairing}

Starting with the left side of~\eqref{eqn:lift-distributes-over-pair}, we first expand definitions.
For any $f_1 : X \botto Y$, $f_2 : X \botto Z$, and $A \subseteq X$,
\begin{align*}
	&\liftmap~(f_1~\pairbot~f_2)~A
\\
	&\tab \equiv \ \liftmap~(\fun{x}{if~(f_1~x = \bot~or~f_2~x = \bot)~\bot~{\pair{f_1~x,f_2~x}}})~A
\\
	&\tab \equiv \ 
		\lzfclet{
			f & \fun{x}{if~(f_1~x = \bot~or~f_2~x = \bot)~\bot~{\pair{f_1~x,f_2~x}}} \\
			A' & domain_\bot~f~A
		}{f\restrict{A'}}
\numberthis
\end{align*}
Next, we replace the definition of $A'$ with one that does not depend on $f$, and rewrite in terms of $\liftmap~f_1$ and $\liftmap~f_2$:
\begin{align*}
	&\liftmap~(f_1~\pairbot~f_2)~A
\\
	&\tab \equiv \ 
		\lzfclet{
			A_1 & (domain_\bot~f_1~A) \\
			A_2 & (domain_\bot~f_2~A) \\
			A' & A_1 \i A_2
		}{\fun{x \in A'}{\pair{f_1~x,f_2~x}}}
\\
	&\tab \equiv \ 
		\lzfclet{
			g_1 & \liftmap~f_1~A \\
			g_2 & \liftmap~f_2~A \\
			A' & (domain~g_1) \i (domain~g_2)
		}{\fun{x \in A'}{\pair{g_1~x,g_2~x}}}
\\
	&\tab \equiv \ \pair{\liftmap~f_1~A, \liftmap~f_2~A}\map
\numberthis
\end{align*}
Substituting $g_1$ for $\liftmap~f_1$ and $g_2$ for $\liftmap~f_2$ gives a definition for $(\pairmap)$ (Figure~\ref{fig:mapping-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-pair} holds.

\subsection{Case: Composition}

The derivation of $(\compmap)$ is similar to that of $(\pairmap)$ but a little more involved.

XXX: include it?

\subsection{Case: Conditional}

Starting with the left side of~\eqref{eqn:lift-distributes-over-if}, we expand definitions, and simplify $f$ by restricting it to a domain for which $f_1~x$ cannot be $\bot$:
\begin{align*}
	&\liftmap~(\ifbot~f_1~f_2~f_3)~A \\
	&\tab \equiv \ 
		\lzfclet{
			f & \fun{x}{\lzfccase{f_1~x}{true & f_2~x \\ false & f_3~x \\ else & \bot}} \\
			A' & domain_\bot~f~A
		}{f\restrict{A'}} \\
	&\tab \equiv \ 
		\lzfclet{
			A_2 & preimage~f_1\restrict{A}~\set{true} \\
			A_3 & preimage~f_1\restrict{A}~\set{false} \\
			f & \fun{x}{if~(f_1~x)~(f_2~x)~(f_3~x)} \\
			A' & domain_\bot~f~(A_2 \uplus A_3)
		}{f\restrict{A'}}
\numberthis
\end{align*}
We finish by converting bottom arrow computations to the mapping arrow and rewriting in terms of $(\uplus\map)$:
\begin{align*}
	&\liftmap~(\ifbot~f_1~f_2~f_3)~A \numberthis
\\
	&\tab \equiv \ 
	\lzfclet{
		g_1 & \liftmap~f_1~A \\
		g_2 & \liftmap~f_2~(preimage~g_1~\set{true}) \\
		g_3 & \liftmap~f_3~(preimage~g_1~\set{false}) \\
		A' & (domain~g_2) \uplus (domain~g_3)
	}{\fun{x \in A'}{if~(x \in domain~g_2)~(g_2~x)~(g_3~x)}}
\\
	&\tab \equiv \
	\lzfclet{
		g_1 & \liftmap~f_1~A \\
		g_2 & \liftmap~f_2~(preimage~g_1~\set{true}) \\
		g_3 & \liftmap~f_3~(preimage~g_1~\set{false})
	}{g_2 \uplus\map g_3}
\end{align*}
Substituting $g_1$ for $\liftmap~f_1$, $g_2$ for $\liftmap~f_2$, and $g_3$ for $\liftmap~f_3$ gives a definition for $\ifmap$ (Figure~\ref{fig:mapping-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-if} holds.

\subsection{Case: Laziness}

Starting with the left side of~\eqref{eqn:lift-distributes-over-lazy}, we first expand definitions:
\begin{align*}
	&\liftmap~(\lazybot~f)~A
\\
	&\tab \equiv \
		\lzfclet{
			A' & domain_\bot~(\fun{x}{f~0~x})~A
		}{(\fun{x}{f~0~x})\restrict{A'}}
\end{align*}
\lzfclang does not have an $\eta$ rule (i.e. $\fun{x}{e~x} \not\equiv e$ because $e$ may diverge), but we can use weaker facts.
If $A \neq \emptyset$, then $domain_\bot~(\fun{x}{f~0~x})~A \equiv domain_\bot~(f~0)~A$.
Further, it diverges iff $f~0$ diverges, which diverges iff $(f~0)\restrict{A'}$ diverges.
Therefore, if $A \neq \emptyset$, we can replace $\fun{x}{f~0~x}$ with $f~0$.
If $A = \emptyset$, then $\liftmap~(\lazybot~f)~A = \emptyset$ (the empty mapping), so
\begin{align*}
	&\liftmap~(\lazybot~f)~A
\\
	&\tab \equiv \
		if~(A = \emptyset)~\emptyset~
		\lzfclet{
			A' & domain_\bot~(f~0)~A
		}{(f~0)\restrict{A'}}
\\
	&\tab \equiv \
		if~(A = \emptyset)~\emptyset~(\liftmap~(f~0)~A)
\end{align*}
Substituting $g~0$ for $\liftmap~(f~0)$ gives a definition for $\lazymap$ (Figure~\ref{fig:mapping-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-lazy} holds.

\subsection{Theorems}

\begin{theorem}[mapping arrow correctness]
$\liftmap$ is an arrow+choice homomorphism.
\end{theorem}
\begin{proof}
By construction.
\end{proof}

\begin{corollary}[semantic correctness]
If $\meaningof{\mathit{e}}_\bot : X \botto Y$, then $lift\map~\meaningof{\mathit{e}}_\bot \equiv \meaningof{\mathit{e}}\map$ and $\meaningof{\mathit{e}}\map : X \mapto Y$.
\end{corollary}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Lazy Preimage Mappings}

On a computer, we will not often have the luxury of testing each function input to see whether it belongs to a preimage set.
Even for finite domains, doing so is often intractable.

If we wish to compute with infinite sets in the language implementation, we will need an abstraction that makes it easy to replace computation on points with computation on sets.
Therefore, in the preimage arrow, we will confine computation on points to \mykeyword{lazy preimage mappings}, or just \emph{preimage mappings}, for which application is like applying $preimage$ to a mapping.
Further on, we will need their ranges to be observable, so we define their type as
\begin{equation}
	X \prepto Y \ ::= \ \pair{Set~Y, Set~Y \tto Set~X}
\end{equation}
Converting a mapping to a lazy preimage mapping:
\begin{equation}
\begin{aligned}
	&pre : (X \pto Y) \tto (X \prepto Y) \\
	&pre~g \ := \ \lzfclet{Y' & range~g \\ p & \fun{B}{preimage~g~B}}{\pair{Y',p}}
\end{aligned}
\end{equation}
Applying a preimage mapping to any subset of its codomain:
\begin{equation}
\begin{aligned}
	&pre@ap : (X \prepto Y) \tto Set~Y \tto Set~X \\
	&pre@ap~\pair{Y',p}~B \ := \ p~(B \i Y')
\end{aligned}
\end{equation}
The necessary property here is that using $pre@ap$ to compute preimages is the same as computing them from a mapping using $preimage$.

\begin{lemma}
Let $g \in X \pto Y$.
For all $B \subseteq Y$ and $Y'$ such that $range~g \subseteq Y' \subseteq Y$,
$preimage~g~(B \i Y') = preimage~g~B$.
\label{lem:preimage-restricted-range}
\end{lemma}

\begin{theorem}[$pre@ap$ computes preimages]
Let $g \in X \pto Y$. For all $B \subseteq Y$, $pre@ap~(pre~g)~B = preimage~g~B$.
\label{thm:pre-like-preimage}
\end{theorem}
\begin{proof}
Expand definitions and apply Lemma~\ref{lem:preimage-restricted-range} with $Y' = range~g$.
\end{proof}

Figure~\ref{fig:preimage-mapping-defs} defines more operations on preimage mappings, including pairing, composition, and disjoint union operations corresponding to the mapping operations in Figure~\ref{fig:mapping-defs}.
Roughly, the correspondence is that $pre$ distributes over mapping operations to yield preimage mapping operations.
The precise correspondence is the subject of the next three theorems, which will be used to derive the preimage arrow from the mapping arrow.

\begin{figure*}
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		&X \prepto Y ::= \pair{Set~Y, Set~Y \tto Set~X}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&pre : (X \mapto Y) \tto (X \prepto Y) \\
		&pre~g \ := \ \pair{range~g, \fun{B}{preimage~g~B}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&pre@ap : (X \prepto Y) \tto Set~Y \tto Set~X \\
		&pre@ap~\pair{Y',p}~B \ := \ p~(B \i Y') 
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&pre@range : (X \prepto Y) \tto Set~Y \\
		&pre@range \ := \ fst
	\end{aligned}
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\pair{\cdot,\cdot}\pre : (X \prepto Y_1) \tto (X \prepto Y_2) \tto (X \prepto Y_1 \times Y_2) \\
		&\pair{\pair{Y_1',p_1},\pair{Y_2',p_2}}\pre \ := \ 
		\lzfclet{
			Y' & Y_1' \times Y_2' \\
			p & \fun{B}{\U\limits_{\pair{y_1,y_2} \in B}(p_1~\set{y_1}) \i (p_2~\set{y_2})} \\
		}{\pair{Y',p}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\circ\pre) : (Y \prepto Z) \tto (X \prepto Y) \tto (X \prepto Z) \\
		&\pair{Z',p_2} \circ\pre h_1 \ := \ \pair{Z', \fun{C}{pre@ap~h_1~(p_2~C)}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\uplus\pre) : (X \prepto Y) \tto (X \prepto Y) \tto (X \prepto Y) \\
		&\lzfcsplit{
			&h_1 \uplus\pre h_2 \ := \ 
			\lzfclet{
					Y' & (pre@range~h_1) \u (pre@range~h_2) \\
					p & \fun{B}{(pre@ap~h_1~B) \uplus (pre@ap~h_2~B)}
				}{\pair{Y',p}}
		}
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Lazy preimage mappings and operations.}
\label{fig:preimage-mapping-defs}
\end{figure*}

First, we need a new notion of equivalence.

\begin{definition}
Two preimage mappings $h_1 : X \prepto Y$ and $h_2 : X \prepto Y$ are equivalent, or $h_1 \equiv h_2$, when $pre@ap~h_1~B = pre@ap~h_2~B$ for all $B \subseteq Y$.
\end{definition}

XXX: define equivalence in terms of equivalence, check observational equivalence in the proofs (specifically divergence)


\subsection{Preimage Mapping Pairing}

XXX: moar wurds in this section

\begin{lemma}[$preimage$ distributes over $\pair{\cdot,\cdot}\map$ and $(\times)$]
Let $g_1 \in X \pto Y_1$ and $g_2 \in X \pto Y_2$.
For all $B_1 \subseteq Y_1$ and $B_2 \subseteq Y_2$, $preimage~\pair{g_1,g_2}\map~(B_1 \times B_2) = (preimage~g_1~B_1) \i (preimage~g_2~B_2)$.
\label{lem:preimage-under-pairing}
\end{lemma}

\begin{theorem}[$pre$ distributes over $\pair{\cdot,\cdot}\map$]
Let $g_1 \in X \pto Y_1$ and $g_2 \in X \pto Y_2$. Then $pre~\pair{g_1,g_2}\map \equiv \pair{pre~g_1,pre~g_2}\pre$.
\label{thm:preimage-mapping-pairing}
\end{theorem}
\begin{proof}
Let $\pair{Y_1',p_1} := pre~g_1$ and $\pair{Y_2',p_2} := pre~g_2$.
Starting from the right side, for all $B \in Y_1 \times Y_2$,
\begin{align*}
	&pre@ap~\pair{pre~g_1,pre~g_2}\pre~B 
\\
	&\tab = \ 
		\lzfclet{
			Y' & Y_1' \times Y_2' \\
			p & \fun{B}{\U\limits_{\pair{y_1,y_2} \in B}(p_1~\set{y_1}) \i (p_2~\set{y_2})} \\
		}{p~(B \i Y')}
\\
	&\tab = \U\limits_{\pair{y_1,y_2} \in B \i (Y_1' \times Y_2')} (p_1~\set{y_1}) \i (p_2~\set{y_2})
\\
	&\tab = \U\limits_{\pair{y_1,y_2} \in B \i (Y_1' \times Y_2')} (preimage~g_1~\set{y_1}) \i (preimage~g_2~\set{y_2})
\\
	&\tab = \U\limits_{y \in B \i (Y_1' \times Y_2')} (preimage~\pair{g_1,g_2}\map~\set{y})
\\
	&\tab = \ preimage~\pair{g_1,g_2}\map~(B \i (Y_1' \times Y_2'))
\\
	&\tab = \ preimage~\pair{g_1,g_2}\map~B
\\
	&\tab = \ pre@ap~(pre~\pair{g_1,g_2}\map)~B
\end{align*}
\end{proof}

\subsection{Preimage Mapping Composition}

XXX: moar wurds in this section

\begin{lemma}[$preimage$ distributes over $(\circ\map)$]
Let $g_1 \in X \pto Y$ and $g_2 \in Y \pto Z$.
For all $C \subseteq Z$, $preimage~(g_2 \circ\map g_1)~C = preimage~g_1~(preimage~g_2~C)$.
\label{lem:preimage-under-composition}
\end{lemma}

\begin{theorem}[$pre$ distributes over $(\circ\map)$]
Let $g_1 \in X \pto Y$ and $g_2 \in Y \pto Z$.
Then $pre~(g_2 \circ\map g_1) \equiv (pre~g_2) \circ\pre (pre~g_1)$.
\label{thm:preimage-mapping-composition}
\end{theorem}
\begin{proof}
Let $\pair{Z',p_2} := pre~g_2$.
Starting from the right side, for all $C \subseteq Z$,
\begin{align*}
	&pre@ap~((pre~g_2) \circ\pre (pre~g_1))~C
\\
	&\tab = \ 
		\lzfclet{
			h & \fun{C}{pre@ap~(pre~g_1)~(p_2~C)} \\
			}{h~(C \i Z')}
\\
	&\tab = \ pre@ap~(pre~g_1)~(p_2~(C \i Z'))
\\
	&\tab = \ pre@ap~(pre~g_1)~(pre@ap~(pre~g_2)~C)
\\
	&\tab = \ preimage~g_1~(preimage~g_2~C)
\\
	&\tab = \ preimage~(g_2 \circ\map g_1)~C
\\
	&\tab = \ pre@ap~(pre~(g_2 \circ\map g_1))~C
\end{align*}
\end{proof}

\subsection{Preimage Mapping Disjoint Union}

XXX: moar wurds in this section

\begin{lemma}[$preimage$ distributes over $(\uplus\map)$]
Let $g_1 \in X \pto Y$ and $g_2 \in X \pto Y$ be disjoint mappings.
For all $B \subseteq Y$, $preimage~(g_1 \uplus\map g_2)~B = (preimage~g_1~B) \uplus (preimage~g_2~B)$.
\label{lem:preimage-under-piecewise}
\end{lemma}

\begin{theorem}[$pre$ distributes over $(\uplus\map)$]
Let $g_1 \in X \pto Y$ and $g_2 \in X \pto Y$ have disjoint domains.
Then $pre~(g_1 \uplus\map g_2) \equiv (pre~g_1) \uplus\pre (pre~g_2)$.
\label{thm:piecewise-preimage-mappings}
\end{theorem}
\begin{proof}
Let $Y_1' := range~g_1$ and $Y_2' := range~g_2$.
Starting from the right side, for all $B \subseteq Y$,
\begin{align*}
	&pre@ap~((pre~g_1) \uplus\pre (pre~g_2))~B
\\
	&\tab = \ 
		\lzfclet{
			\! Y' & Y_1' \u Y_2' \\
			h & \fun{B}{(pre@ap~(pre~g_1)~B) \uplus (pre@ap~(pre~g_2)~B)}
		}{h~(B \i Y')}
\\
	&\tab = \ \lzfcsplit{&(pre@ap~(pre~g_1)~(B \i (Y_1' \u Y_2')))\ \uplus\\ &(pre@ap~(pre~g_2)~(B \i (Y_1' \u Y_2')))}
\\
	&\tab = \ \lzfcsplit{&(preimage~g_1~(B \i (Y_1' \u Y_2')))\ \uplus\\ &(preimage~g_2~(B \i (Y_1' \u Y_2')))}
\\
	&\tab = \ preimage~(g_1 \uplus\map g_2)~(B \i (Y_1' \u Y_2'))
\\
	&\tab = \ preimage~(g_1 \uplus\map g_2)~B
\\
	&\tab = \ pre@ap~(pre~(g_1 \uplus\map g_2))~B
\end{align*}
\end{proof}

\section{Deriving the Preimage Arrow}

XXX: intro

\begin{equation}
	X \preto Y \ ::= \ Set~X \tto (X \prepto Y)
\end{equation}

\begin{equation}
\begin{aligned}
	&\liftpre : (X \mapto Y) \tto (X \preto Y) \\
	&\liftpre~g~A \ := \ pre~(g~A)
\end{aligned}
\end{equation}

\begin{definition}[Preimage arrow equivalence]
Two preimage arrow computations $h_1 : X \preto Y$ and $h_2 : X \preto Y$ are equivalent, or $h_1 \equiv h_2$, when 
$h_1~A \equiv h_2~A$ for all $A \subseteq X$.
\end{definition}

As with $\arrmap$, defining $\arrpre$ as a composition meets~\eqref{eqn:lift-distributes-over-arr}.
The following subsections derive $(\pairpre)$, $(\comppre)$, $\ifpre$ and $\lazypre$ from their corresponding mapping arrow combinators, in a way that ensures $\liftpre$ is an arrow+choice homomorphism from the mapping arrow to the preimage arrow. Figure~\ref{fig:preimage-arrow-defs} contains the resulting definitions.

\begin{figure*}
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		&X \preto Y ::= Set~X \tto (X \prepto Y)
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&\arrpre : (X \tto Y) \tto (X \preto Y) \\
		&\arrpre \ := \ \liftpre \circ \arrmap
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\comppre) : (X \preto Y) \tto (Y \preto Z) \tto (X \preto Z) \\
		&(h_1~\comppre~h_2)~A \ := \ 
			\lzfclet{
				h_1' & h_1~A \\
				h_2' & h_2~(pre@range~h_1')
			}{h_2' \circ\pre h_1'}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&(\pairpre) : (X \preto Y) \tto (X \preto Z) \tto (X \preto Y \times Z) \\
		&(h_1~\pairpre~h_2)~A \ := \ \pair{h_1~A,h_2~A}\pre
	\end{aligned}
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&\ifpre: (X \preto Bool) \tto (X \preto Y) \tto (X \preto Y) \tto (X \preto Y) \\
		&\ifpre~h_1~h_2~h_3~A \ := \ 
			\lzfclet{
				h_1' & h_1~A \\
				h_2' & h_2~(pre@ap~h_1'~\set{true}) \\
				h_3' & h_3~(pre@ap~h_1'~\set{false})
			}{h_2' \uplus\pre h_3'}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&\lazypre : (1 \tto (X \preto Y)) \tto (X \preto Y) \\
		&\lazypre~h~A \ := \ if~(A = \emptyset)~(pre~\emptyset)~(h~0~A)
	\end{aligned} \\
\\[-6pt]
\hline
\\[-6pt]
	&\begin{aligned}[t]
		&\liftpre : (X \mapto Y) \tto (X \preto Y) \\
		&\liftpre~g~A \ := \ pre~(g~A)
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Preimage arrow definitions.}
\label{fig:preimage-arrow-defs}
\end{figure*}

\subsection{Case: Pairing}

Starting with the left side of~\eqref{eqn:lift-distributes-over-pair}, we expand definitions, apply Theorem~\ref{thm:preimage-mapping-pairing}, and rewrite in terms of $\liftpre$:
\begin{align*}
	&pre@ap~(\liftpre~(g_1~\pairmap~g_2)~A)~B
\\
	&\tab \equiv \ pre@ap~(pre~\pair{g_1~A, g_2~A}\map)~B
\\
	&\tab \equiv \ pre@ap~\pair{pre~(g_1~A), pre~(g_2~A)}\pre~B
\\
	&\tab \equiv \ pre@ap~\pair{\liftpre~g_1~A, \liftpre~g_2~A}\pre~B
\end{align*}
Substituting $h_1$ for $\liftpre~g_1$ and $h_2$ for $\liftpre~g_2$, and removing the application of $pre@ap$ from both sides of the equivalence gives a definition of $(\pairpre)$ (Figure~\ref{fig:preimage-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-pair} holds.

\subsection{Case: Composition}

Starting with the left side of~\eqref{eqn:lift-distributes-over-comp}, we expand definitions, apply Theorem~\ref{thm:preimage-mapping-composition} and rewrite in terms of $\liftpre$:
\begin{align*}
	&pre@ap~(\liftpre~(g_1~\compmap~g_2)~A)~C
\\
	&\tab \equiv \ 
		\lzfclet{
			g_1' & g_1~A \\
			g_2' & g_2~(range~g_1')
		}{pre@ap~(pre~(g_2' \circ\map g_1'))~C}
\\
	&\tab \equiv \ 
		\lzfclet{
			g_1' & g_1~A \\
			g_2' & g_2~(range~g_1')
		}{pre@ap~((pre~g_1') \circ\pre (pre~g_2'))~C}
\\
	&\tab \equiv \
		\lzfclet{
			h_1 & \liftpre~g_1~A \\
			h_2 & \liftpre~g_2~(pre@range~h_1)
		}{pre@ap~(h_2 \circ\pre h_1)~C}
\numberthis
\end{align*}
Substituting $h_1$ for $\liftpre~g_1$ and $h_2$ for $\liftpre~g_2$, and removing the application of $pre@ap$ from both sides of the equivalence gives a definition of $(\comppre)$ (Figure~\ref{fig:preimage-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-comp} holds.

\subsection{Case: Conditional}

Starting with the left side of~\eqref{eqn:lift-distributes-over-if}, we expand terms, apply Theorem~\ref{thm:piecewise-preimage-mappings}, rewrite in terms of $\liftpre$, and apply Theorem~\ref{thm:pre-like-preimage} in the definitions of $h_2$ and $h_3$:
\begin{align*}
	&pre@ap~(\liftpre~(\ifmap~g_1~g_2~g_3)~A)~B
\\
	&\tab \equiv \ 
		\lzfclet{
			g_1' & g_1~A \\
			g_2' & g_2~(preimage~g_1'~\set{true}) \\
			g_3' & g_3~(preimage~g_1'~\set{false})
		}{pre@ap~(pre~(g_2' \uplus\map g_3'))~B}
\\
	&\tab \equiv \ 
		\lzfclet{
			g_1' & g_1~A \\
			g_2' & g_2~(preimage~g_1'~\set{true}) \\
			g_3' & g_3~(preimage~g_1'~\set{false})
		}{pre@ap~((pre~g_2') \uplus\pre (pre~g_3'))~B}
\\
	&\tab \equiv \ 
		\lzfclet{
			h_1 & \liftpre~g_1~A \\
			h_2 & \liftpre~g_2~(pre@ap~h_1~\set{true}) \\
			h_3 & \liftpre~g_3~(pre@ap~h_1~\set{false})
		}{pre@ap~(h_2 \uplus\pre h_3)~B}
\end{align*}
Substituting $h_1$ for $\liftpre~g_1$, $h_2$ for $\liftpre~g_2$ and $h_3$ for $\liftpre~g_3$, and removing the application of $pre@ap$ from both sides of the equivalence gives a definition of $\ifpre$ (Figure~\ref{fig:preimage-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-if} holds.

\subsection{Case: Laziness}

Starting with the left side of~\eqref{eqn:lift-distributes-over-lazy}, expand definitions, distribute $pre$ over the branches of $if$, and rewrite in terms of $\liftpre~(g~0)$:
\begin{align*}
	&pre@ap~(\liftpre~(\lazymap~g)~A)~B
\\
	&\tab\equiv \
		\lzfclet{
			g' & if~(A = \emptyset)~\emptyset~(g~0~A)
		}{pre@ap~(pre~g')~B}
\\
	&\tab\equiv \
		\lzfclet{
			h & if~(A = \emptyset)~(pre~\emptyset)~(pre~(g~0~A))
		}{pre@ap~h~B}
\\
	&\tab\equiv \
		\lzfclet{
			h & if~(A = \emptyset)~(pre~\emptyset)~(\liftpre~(g~0)~A)
		}{pre@ap~h~B}
\end{align*}
Substituting $h~0$ for $\liftpre~(g~0)$ and removing the application of $pre@ap$ from both sides of the equivalence gives a definition for $\lazypre$ (Figure~\ref{fig:preimage-arrow-defs}) for which~\eqref{eqn:lift-distributes-over-lazy} holds.

\subsection{Theorems}

\begin{theorem}[preimage arrow correctness]
$\liftpre$ is an arrow+choice homomorphism.
\label{thm:liftpre-homomorphism}
\end{theorem}
\begin{proof}
By construction.
\end{proof}

\begin{corollary}[semantic correctness]
If $\meaningof{\mathit{e}}\map : X \mapto Y$, then $\liftpre~\meaningof{\mathit{e}}\map \equiv \meaningof{\mathit{e}}\pre$ and $\meaningof{\mathit{e}}\pre : X \preto Y$.
\label{cor:preimage-arrow-correctness}
\end{corollary}

In particular, $\meaningof{\mathit{e}}\pre$ correctly computes preimages under the interpretation of $\mathit{e}$ as a function from a random source.

\section{Preimages Under Partial Functions}

Probabilistic functions that may diverge, but converge with probability 1, are common.
They come up not only when practitioners want to build data with random size or structure, but in simpler circumstances as well.

Suppose $boolean~p$ returns $true$ with probability $p$, by retrieving a number $x_i \in [0,1]$ from a uniform random source $x$ and returning $true$ when $x_i < p$.
The following recursive function, which defines the well-known \keyword{geometric distribution}, counts the number of times $boolean~p$ is $false$:
\begin{equation}
	geometric~p \ := \ if~(boolean~p)~0~(1 + geometric~p)
\label{eqn:geometric-def}
\end{equation}
While $geometric~p$ for any $p > 0$ may diverge, the probability of always taking the false branch is $(1-p) \times (1-p) \times (1-p) \times \cdots = 0$.
Divergence with probability $0$ simply does not happen in practice.

Suppose we interpret~\eqref{eqn:geometric-def} as $h : X \preto \Nat$, a preimage arrow computation from random sources in $X$ to natural numbers, and that we have a probability measure $P \in \powerset~X \pto [0,1]$.
We could compute the probability of any output set $N \subseteq \Nat$ using $P~(h~A~N)$, where $A \subseteq X$ and $P~A = 1$. We have three hurdles to overcome:
\begin{enumerate}
	\item Ensuring $h~A$ converges.
	\item Determining how $boolean~p$ indexes numbers in $x$.
	\item Ensuring each $x \in X$ contains enough random numbers.
\end{enumerate}
Ensuring $h~A$ converges is the most difficult, but will provide an expression indexing scheme for unrolled programs to help with the other two.

\subsection{Expression Indexing}

XXX: overall idea: define an arrow transformer that assigns every combinator a unique index; define another arrow transformer that threads 

threads an infinite vector of random numbers through its computations

\begin{definition}[binary indexing scheme]
Let $J$ be an index set and $j_0 \in J$ a distinguished element.
Let $left : J \tto J$ and $right : J \tto J$ be total functions.
If for any finite composition $f$ of $left$ and $right$, $f~j_0$ is unique, then $J$, $j_0$, $left$ and $right$ define a \mykeyword{binary indexing scheme}.
\end{definition}

For example, let $J$ be the set of lists of booleans, $j_0$ the empty list, and define
\begin{equation}
\begin{aligned}
	left~xs &\ := \ \pair{true,xs}
\\
	right~xs &\ := \ \pair{false,xs}
\end{aligned}
\end{equation}
Alternatively, let $J := (0,1) \i \Rat$, $j_0 := \tfrac{1}{2}$ and
\begin{equation}
\begin{aligned}
	left~(p/q) &\ := \ (p-\tfrac{1}{2})/q
\\
	right~(p/q) &\ := \ (p+\tfrac{1}{2})/q
\end{aligned}
\end{equation}

If $J$ ... then $x \in J \to [0,1]$ 


\subsection{Applicative Store-Passing}


\section{Approximating Preimage Arrow}

XXX: $\arrpre$ is generally uncomputable, but we don't need that many lifts; Figure~\ref{fig:extra-preimage-arrow-defs} has the rest of the non-arithmetic ones we'll need

XXX: figure out a good way to present the following info

Figure~\ref{fig:mapping-arrow-defs}:
\begin{itemize}
	\item $pre$: can't implement
	\item $pre@ap$: need $\i$
	\item $\pair{\cdot,\cdot}\pre$: approximate; need $\times$ and $\i$
	\item $\circ\pre$: no change
	\item $\uplus\pre$: approximate; need join
\end{itemize}

Figure~\ref{fig:preimage-arrow-defs}:
\begin{itemize}
	\item $\arrpre$ (and $\liftpre$): can't implement
	\item $\comppre$: no change
	\item $\pairpre$: use approximating $\pair{\cdot,\cdot}\pre$
	\item $\ifpre$: need $\set{true}$ and $\set{false}$; use approximating $\uplus\pre$
	\item $\lazypre$: need $(= \emptyset)$, $(pre~\emptyset)$
\end{itemize}

Figure~\ref{fig:extra-preimage-arrow-defs}:
\begin{itemize}
	\item $id\pre$: no change
	\item $const\pre$: need $\set{y}$, $(= \emptyset)$, $\emptyset$
	\item $fst\pre$ and $snd\pre$: need projections, $i$, $\times$
	\item $\pi\pre$: need projections, $\i$, arbitrary products
\end{itemize}

\begin{figure*}[t]\centering
\begin{align*}
\begin{aligned}[t]
	&\begin{aligned}[t]
		&id\pre : X \preto X \\
		&id\pre~A \ := \ \pair{A,\fun{B}{B}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&const\pre : Y \tto X \preto Y \\
		&const\pre~y~A \ := \ \pair{\set{y},\fun{B}{if~(B = \emptyset)~\emptyset~A}}
	\end{aligned} \\
\\[-6pt]
&\begin{aligned}
	&\pi\pre : J \tto (J \to X) \preto X \\
	&\pi\pre~j~A \ := \ 
		\lzfclet{
			A_j & proj~j~A \\
			p & \fun{B}{A \i \prod_{i \in J} if~(j = i)~B~(proj~i~A)}
		}{\pair{A_j,p}}
\end{aligned}
\end{aligned}
&\tab\tab\tab
\begin{aligned}[t]
	&\begin{aligned}[t]
		&fst\pre : \pair{X,Y} \preto X \\
		&fst\pre~A \ := \ 
			\lzfclet{
				A_1 & image~fst~A \\
				A_2 & image~snd~A
			}{\pair{A_1,\fun{B}{A \i (B \times A_2)}}}
	\end{aligned} \\
\\[-6pt]
	&\begin{aligned}[t]
		&snd\pre : \pair{X,Y} \preto Y \\
		&snd\pre~A \ := \ 
			\lzfclet{
				A_1 & image~fst~A \\
				A_2 & image~snd~A
			}{\pair{A_2,\fun{B}{A \i (A_1 \times B)}}}
	\end{aligned}
\end{aligned}
\end{align*}
\hrule
\caption{Specific instances of $\arrpre~f$}
\label{fig:extra-preimage-arrow-defs}
\end{figure*}

\section{Computable Approximation}





%\appendix
%\section{Appendix Title}
%This is the text of the appendix, if you need one.

%\acks
%Acknowledgments, if needed.

\bibliographystyle{abbrvnat}
\bibliography{plt}

\end{document}
